{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import analyze # takes some time since inits hax\n",
    "from channel_dict import channel_dict\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "cursor has 1208 runs\n",
      "Number of runs and most recent run of each type\n",
      "blank 46 18382\n",
      "bottom 46 18383\n",
      "topbulk 46 18384\n",
      "topring 46 18385\n",
      "18189 18190 18191 18192\n"
     ]
    }
   ],
   "source": [
    "from make_runlist_new import write_spe_lists\n",
    "\n",
    "#dry run\n",
    "write_spe_lists(write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "Number of runs and most recent run of each type\n",
      "blank 46 18382\n",
      "bottom 46 18383\n",
      "topbulk 46 18384\n",
      "topring 46 18385\n",
      "['./runlists/runlist_18190_18191_18192.txt']\n"
     ]
    }
   ],
   "source": [
    "#writes new runlists\n",
    "written=write_spe_lists(write=True)\n",
    "print(written)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This will take some time to run as job submission takes several hours. Alternatively, in the terminal you can run ./submit_jobs.sh ./runlists/[runlist name] for a single runlist, or ./large_submission.sh to submit jobs for all runlists in ./runlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit_job(file):\n",
    "    command = \"./submit_jobs.sh %s\" % file\n",
    "    print(command)\n",
    "    !{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./submit_jobs.sh ./runlists/runlist_18190_18191_18192.txt\n",
      "noise run: 18189\n",
      "LED runs: 18190\n",
      "18191\n",
      "18192\n",
      "Deactivate:Unsetting ROOT environment variables..\n",
      "Activate: ROOT has been sourced. Environment settings are ready. \n",
      "ROOTSYS=/project/lgrandi/anaconda3/envs/pax_v6.8.0\n",
      "ls: cannot access /project/lgrandi/xenon1t/spe_acceptance/rawdata/180406_1029: No such file or directory\n",
      "ls: cannot access /project/lgrandi/xenon1t/spe_acceptance/rawdata/180406_1044: No such file or directory\n",
      "ls: cannot access /project/lgrandi/xenon1t/spe_acceptance/rawdata/180406_1113: No such file or directory\n",
      "ls: cannot access /project/lgrandi/xenon1t/spe_acceptance/rawdata/180406_1203: No such file or directory\n",
      "Submitted batch job 45238129\n"
     ]
    }
   ],
   "source": [
    "for f in written:\n",
    "    submit_job(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acc Vs Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating acceptance and error data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hax\n",
    "#hax already initiated when analyze is imported\n",
    "\n",
    "from spe_acceptance import data_dir_base, rawdata_dir\n",
    "\n",
    "\n",
    "def data_exists(run_number):\n",
    "    data_path=os.path.join(data_dir_base, 'run_%05d.h5' %int(run_number))\n",
    "    return os.path.exists(data_path)\n",
    "\n",
    "def all_data_exists(runlist):\n",
    "    return all([data_exists(run) for run in runlist])\n",
    "\n",
    "def file_to_list(runlist_file):\n",
    "    return [int(run) for run in runlist_file.split('.')[0].split('_')[1:4]]\n",
    "\n",
    "def get_run_time(run):\n",
    "    return hax.runs.datasets[hax.runs.datasets.number == run].start.values[0]\n",
    "    \n",
    "def find_file(run):\n",
    "    return [f for f in os.listdir('runlists') if any(int(run)==elem for elem in file_to_list(f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieves previously loaded data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists for:  ['runlist_9549_9550_9551.txt', 'runlist_12587_12588_12589.txt', 'runlist_7350_7351_7352.txt', 'runlist_6909_6910_6911.txt', 'runlist_6550_6551_6552.txt', 'runlist_7067_7068_7069.txt', 'runlist_12768_12769_12770.txt', 'runlist_11429_11430_11431.txt', 'runlist_7447_7448_7449.txt', 'runlist_16984_16985_16986.txt', 'runlist_10696_10697_10698.txt', 'runlist_6957_6958_6959.txt', 'runlist_13433_13434_13435.txt', 'runlist_12046_12047_12048.txt', 'runlist_17454_17455_17456.txt', 'runlist_7968_7969_7970.txt', 'runlist_7646_7647_7648.txt', 'runlist_11625_11626_11627.txt', 'runlist_10133_10134_10135.txt', 'runlist_8448_8449_8450.txt', 'runlist_7758_7759_7760.txt', 'runlist_6938_6939_6940.txt', 'runlist_16343_16344_16345.txt', 'runlist_9604_9605_9606.txt', 'runlist_9033_9034_9036.txt', 'runlist_7485_7486_7487.txt', 'runlist_11069_11070_11071.txt', 'runlist_7569_7570_7571.txt', 'runlist_16701_16702_16703.txt', 'runlist_8921_8922_8923.txt', 'runlist_15625_15627_15628.txt', 'runlist_14192_14193_14195.txt', 'runlist_13300_13301_13303.txt', 'runlist_15987_15988_15989.txt', 'runlist_6169_6170_6171.txt', 'runlist_6753_6754_6755.txt', 'runlist_7912_7913_7914.txt', 'runlist_12130_12131_12132.txt', 'runlist_5242_5244_5243.txt', 'runlist_5152_5154_5153.txt', 'runlist_8154_8155_8156.txt', 'runlist_13837_13838_13839.txt', 'runlist_17587_17588_17589.txt', 'runlist_12318_12319_12320.txt', 'runlist_8267_8268_8269.txt', 'runlist_10796_10797_10798.txt', 'runlist_6358_6359_6360.txt', 'runlist_14088_14089_14090.txt', 'runlist_5755_5756_5757.txt', 'runlist_9697_9698_9699.txt', 'runlist_13128_13129_13130.txt', 'runlist_5442_5444_5443.txt', 'runlist_10297_10298_10299.txt', 'runlist_9112_9113_9114.txt', 'runlist_11535_11536_11537.txt', 'runlist_17862_17863_17864.txt', 'runlist_9797_9798_9799.txt', 'runlist_11733_11734_11736.txt', 'runlist_12946_12947_12948.txt', 'runlist_8735_8736_8737.txt', 'runlist_7268_7269_7270.txt', 'runlist_16523_16524_16526.txt', 'runlist_10877_10878_10879.txt', 'runlist_8840_8841_8842.txt', 'runlist_7680_7681_7682.txt', 'runlist_6984_6985_6986.txt', 'runlist_11813_11814_11815.txt', 'runlist_15085_15086_15087.txt', 'runlist_16237_16238_16239.txt', 'runlist_10524_10525_10526.txt', 'runlist_8350_8351_8352.txt', 'runlist_5646_5648_5647.txt', 'runlist_6446_6447_6448.txt', 'runlist_8069_8070_8071.txt', 'runlist_15811_15812_15813.txt', 'runlist_10064_10065_10066.txt', 'runlist_17249_17250_17251.txt', 'runlist_14369_14370_14371.txt', 'runlist_17782_17783_17784.txt', 'runlist_7795_7796_7797.txt', 'runlist_6834_6835_6836.txt', 'runlist_14733_14734_14735.txt', 'runlist_10610_10611_10612.txt', 'runlist_9217_9218_9219.txt', 'runlist_5039_5041_5040.txt', 'runlist_15268_15270_15271.txt', 'runlist_13657_13658_13659.txt', 'runlist_12511_12512_12513.txt', 'runlist_11352_11353_11354.txt', 'runlist_8545_8546_8547.txt', 'runlist_14555_14556_14557.txt', 'runlist_9299_9300_9301.txt', 'runlist_15420_15421_15422.txt', 'runlist_8627_8628_8629.txt', 'runlist_12398_12399_12400.txt', 'runlist_14907_14908_14909.txt', 'runlist_5557_5559_5558.txt', 'runlist_12211_12213_12214.txt', 'runlist_11277_11278_11279.txt', 'runlist_10986_10987_10988.txt', 'runlist_5358_5360_5359.txt', 'runlist_17939_17940_17942.txt', 'runlist_7100_7101_7103.txt', 'runlist_6892_6893_6894.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/lgrandi/anaconda3/envs/pax_v6.8.0/lib/python3.4/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/project/lgrandi/anaconda3/envs/pax_v6.8.0/lib/python3.4/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#all runlists\n",
    "runlists = [f for f in os.listdir('./runlists')]\n",
    "bottom_runs = []\n",
    "accs = []\n",
    "\n",
    "ch_acc_dict={}\n",
    "ch_err_l={}\n",
    "ch_err_u={}\n",
    "\n",
    "upper_errs=[]\n",
    "lower_errs=[]\n",
    "errors = []\n",
    "\n",
    "missing_runs = []\n",
    "LED_off = []\n",
    "resubmit_files = []\n",
    "\n",
    "with open('/project/lgrandi/xenon1t/spe_acceptance/ch_data/ch_data.pkl', 'rb') as cd:\n",
    "    if os.stat('/project/lgrandi/xenon1t/spe_acceptance/ch_data/ch_data.pkl').st_size==0:\n",
    "        print('No data in pickle file')\n",
    "        data=[]\n",
    "    else:\n",
    "        data=pickle.load(cd)\n",
    "saved_runlists=[]\n",
    "\n",
    "for runlist in runlists:\n",
    "    runs=file_to_list(runlist)\n",
    "    if not all_data_exists(runs):\n",
    "        resubmit_files.append(runlist)\n",
    "        for r in runs:\n",
    "            if not data_exists(r):\n",
    "                missing_runs.append(r)\n",
    "        continue\n",
    "    else:\n",
    "        bottom_runs.append(runs[0])\n",
    "\n",
    "for cd in data:\n",
    "    if len(data)==0:\n",
    "        continue\n",
    "        \n",
    "    saved_runlists.append(cd.runlist)\n",
    "    \n",
    "    acc=cd.acc\n",
    "    on_acc=cd.on_acc\n",
    "    acc_errs_l=cd.acc_errs_l\n",
    "    acc_errs_u=cd.acc_errs_u\n",
    "    acc_sys=cd.acc_sys\n",
    "    acc_stat=cd.acc_stat\n",
    "    occ=cd.occ\n",
    "    on_occ=cd.on_occ\n",
    "    occ_sys=cd.occ_sys\n",
    "    occ_stat=cd.occ_stat\n",
    "    \n",
    "    on_channels = np.where(occ > 0.05)[0]\n",
    "        \n",
    "    if len(on_channels) < 200:\n",
    "        LED_off.append(cd.runlist)\n",
    "    \n",
    "    ch_acc_dict[cd.runlist]=acc\n",
    "    \n",
    "    #mean along axis=1 to get by channel acc, errs\n",
    "    ch_err_l[cd.runlist]=np.mean(acc_errs_l**2, axis=1)\n",
    "    ch_err_u[cd.runlist]=np.mean(acc_errs_u**2, axis=1)\n",
    "    \n",
    "    runlist = file_to_list(cd.runlist)\n",
    "    \n",
    "    bottom_run = runlist[0]\n",
    "    topbulk_run = runlist[1]\n",
    "    topring_run = runlist[2]\n",
    "    \n",
    "    accs.append(np.mean(on_acc))\n",
    "    #mean along axis=0 to get average per runlist\n",
    "    lower_errs.append(np.mean(acc_errs_l**2))\n",
    "    upper_errs.append(np.mean(acc_errs_u**2))\n",
    "        \n",
    "print(\"Data already exists for: \", saved_runlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculates acceptance, errors for new runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newest Runlist:  runlist_18190_18191_18192.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awalsh272/SPE/SPE/analyze.py:72: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sigma_corr_noise=corr_noise*np.sqrt( (sigma_corr/corrections)**2 + (sigma_noise/noise)**2)\n"
     ]
    }
   ],
   "source": [
    "#just newest runlist\n",
    "\n",
    "newest_runlist= find_file(sorted(bottom_runs)[-1])[0]\n",
    "print(\"Newest Runlist: \", newest_runlist)\n",
    "runlist = file_to_list(newest_runlist)\n",
    "\n",
    "if str(newest_runlist) not in saved_runlists:\n",
    "    if not all_data_exists(runlist):\n",
    "        resubmit_files.append(newest_runlist)\n",
    "        for r in runlist:\n",
    "            if not data_exists(r):\n",
    "                missing_runs.append(r)\n",
    "            continue\n",
    "\n",
    "\n",
    "    bottom_run = runlist[0]\n",
    "    topbulk_run = runlist[1]\n",
    "    topring_run = runlist[2]\n",
    "\n",
    "    thresholds = analyze.get_thresholds(analyze.find_regular_run(bottom_run))\n",
    "\n",
    "    acc, acc_errs, acc_sys, acc_stat = analyze.acceptance_3runs(bottom_run, topbulk_run, topring_run, thresholds)\n",
    "    occ, occ_sys, occ_stat = analyze.occupancy_3runs(bottom_run, topbulk_run, topring_run)\n",
    "\n",
    "    on_channels = np.where(occ > 0.05)[0]\n",
    "\n",
    "    if len(on_channels) < 200:\n",
    "        LED_off.append(newest_runlist)\n",
    "\n",
    "    on_acc = acc[on_channels]\n",
    "    on_occ = occ[on_channels]\n",
    "\n",
    "    ch_acc_dict[newest_runlist]=acc\n",
    "\n",
    "    acc_errs_l = acc_errs[0]\n",
    "    acc_errs_u = acc_errs[1]\n",
    "\n",
    "    ch_err_l[newest_runlist]=np.mean(acc_errs_l**2, axis=1)\n",
    "    ch_err_u[newest_runlist]=np.mean(acc_errs_u**2, axis=1)\n",
    "\n",
    "    accs.append(np.mean(on_acc))\n",
    "    lower_errs.append(np.mean(acc_errs_l**2))\n",
    "    upper_errs.append(np.mean(acc_errs_u**2))\n",
    "    bottom_runs.append(bottom_run)\n",
    "\n",
    "    cd=analyze.ch_data(newest_runlist, get_run_time(bottom_run), acc, on_acc, acc_errs_l, acc_errs_u, acc_sys, acc_stat, occ, on_occ, occ_sys, occ_stat)\n",
    "    data.append(cd)\n",
    "\n",
    "else:\n",
    "    print(\"Data already in pickle file\")\n",
    "\n",
    "errors=np.array([lower_errs, upper_errs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dumps all data into pickle file, prints runs with LED off and runs with missing data, deletes raw data for processed runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spe_acceptance import change_permissions\n",
    "\n",
    "os.remove('/project/lgrandi/xenon1t/spe_acceptance/ch_data/ch_data.pkl')\n",
    "with open('/project/lgrandi/xenon1t/spe_acceptance/ch_data/ch_data.pkl', 'wb') as cd:\n",
    "    pickle.dump(data, cd)\n",
    "change_permissions('/project/lgrandi/xenon1t/spe_acceptance/ch_data/ch_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Delete raw data after processed data is in the pickle file\n",
    "from get_name import get_name\n",
    "no_data=[]\n",
    "for runlist in runlists:\n",
    "    with open(os.path.join('./runlists', runlist)) as r:\n",
    "        for run in r.readlines():\n",
    "            name=get_name(int(run))\n",
    "            path=os.path.join(rawdata_dir, name)\n",
    "            if not os.path.exists(path):\n",
    "                no_data.append(run)\n",
    "                continue\n",
    "            if os.path.exists(path):\n",
    "                if os.path.exists(os.path.join(data_dir_base, run)):\n",
    "                    shutil.rmtree(path)\n",
    "                    print(\"Deleting raw data for: \", run, name)\n",
    "    \n",
    "print(\"These runs are missing data: \", missing_runs)\n",
    "print(\"LED likely off for these files: \", LED_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resubmits jobs for runs missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in resubmit_files:\n",
    "    runs=file_to_list(f)\n",
    "    submit=os.path.join('./runlists', f)\n",
    "    if runs[0]<6731:\n",
    "        continue\n",
    "    submit_job(submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptance dataframe with channels as row index, runlists as column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_df=pd.DataFrame(ch_acc_dict)\n",
    "channels_df=pd.DataFrame({\"channels\": [i for i in range(0,248)]})\n",
    "ch_df=pd.concat([acc_df, channels_df], axis=1)\n",
    "ch_df.set_index('channels', inplace=True)\n",
    "ch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lower, upper errors dataframes with channels as row index, runlist as column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lerr_df=pd.DataFrame(ch_err_l)\n",
    "ch_lerr_df=pd.concat([lerr_df, channels_df], axis=1)\n",
    "ch_lerr_df.set_index('channels', inplace=True)\n",
    "ch_lerr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uerr_df=pd.DataFrame(ch_err_u)\n",
    "ch_uerr_df=pd.concat([uerr_df, channels_df], axis=1)\n",
    "ch_uerr_df.set_index('channels', inplace=True)\n",
    "ch_uerr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newest Runlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finds newest runlist, gets acceptance and occupancy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channels that look off, note that this includes both channels that are actually off and channels that aren't performing properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prints list of off pmts\n",
    "my_off = np.where(occ < 0.05)[0]\n",
    "print(\"Channels that look off for %s: \" %newest_runlist , my_off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptance histogram for one runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the acceptance of one runlist\n",
    "plt.hist(on_acc, bins=50, range=(0,1.1))\n",
    "plt.title(\"Acceptance for %s \" %newest_runlist)\n",
    "plt.xlabel(\"SPE Acceptance\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupancy histogram for one runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the occupancy of one runlist\n",
    "plt.hist(on_occ, bins=50, range=(0,1.1))\n",
    "plt.title(\"Occupancy for %s \" %newest_runlist)\n",
    "plt.xlabel(\"Occupancy\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlim(0,0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceptance of all channels for the newest runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot acceptance of each channel\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.errorbar(on_channels, on_acc, yerr=[ch_lerr_df.loc[on_channels, newest_runlist], ch_uerr_df.loc[on_channels,newest_runlist]], marker='.', linestyle='none')\n",
    "plt.ylabel('Acceptance Fraction')\n",
    "plt.xlabel('Channel #')\n",
    "plt.title('Acc by Ch for %s' %newest_runlist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prints low acceptance channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prints list of low acc ch\n",
    "cha_dict_new={}\n",
    "\n",
    "for ch, a in zip(on_channels, on_acc):\n",
    "    cha_dict_new[a]=ch\n",
    "    \n",
    "new_low_acc_ch=[]\n",
    "for a in on_acc:\n",
    "    if a<0.5:\n",
    "        new_low_acc_ch.append(cha_dict_new[a])\n",
    "        \n",
    "print('Low acc ch for %s: ' %newest_runlist, new_low_acc_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean, Median, Errors for runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maybe including off channels in mean\n",
    "acc_mean=np.nanmean(ch_acc_dict[newest_runlist][on_channels])\n",
    "acc_median=np.nanmedian(ch_acc_dict[newest_runlist])\n",
    "\n",
    "print(\"Runlist: \", newest_runlist)\n",
    "print(\"Mean Acceptance: \", acc_mean)\n",
    "print(\"Median Acceptance: \", acc_median)\n",
    "print(\"Errors [l,u]: \", [np.nanmean(ch_err_l[newest_runlist]), np.nanmean(ch_err_u[newest_runlist])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Acceptance per Runlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot acceptance vs time using full runlists\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "fmt = mdates.DateFormatter('%Y-%m')\n",
    "\n",
    "bottom_runs = np.array(bottom_runs)\n",
    "dates = np.array([get_run_time(run) for run in bottom_runs])\n",
    "accs = np.array(accs)\n",
    "\n",
    "noisy_runs = [12768, 13837]\n",
    "sr1 = np.where(bottom_runs > 6731)\n",
    "sr1 = [i for i in sr1[0] if bottom_runs[i] not in noisy_runs]\n",
    "plot_dates = dates[sr1]\n",
    "plot_runs = bottom_runs[sr1]\n",
    "plot_accs = accs[sr1]\n",
    "plot_errors = [errors[0][sr1],errors[1][sr1]]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "ax.errorbar(plot_dates, plot_accs, yerr=plot_errors, linestyle='None', marker='.')\n",
    "ax.set_ylim(0.75, 1.0)\n",
    "plt.xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=20)\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "ax.grid()\n",
    "ax.set_xlabel('date')\n",
    "ax.set_ylabel('spe acceptance')\n",
    "plt.title(\"Acceptance vs Time\")\n",
    "plt.savefig('new_moneyplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean, Median, Errors for all runlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add table of mean/median w errors for time evo, print days that are outliers\n",
    "\n",
    "evo_mean=np.nanmean(plot_accs)\n",
    "evo_median=np.nanmedian(plot_accs)\n",
    "evo_errs=[np.nanmean(plot_errors[0]), np.nanmean(plot_errors[1])]\n",
    "\n",
    "evo_std=np.nanstd(plot_accs)\n",
    "\n",
    "print(\"All Runlists\")\n",
    "print(\"Mean :\", evo_mean)\n",
    "print(\"Median :\", evo_median)\n",
    "print(\"Errors [l, u]: \", evo_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance for Individual Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots acceptances of one channel for all runlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ch=0\n",
    "\n",
    "#list of lists of runlists\n",
    "sr1_rl=[find_file(i) for i in bottom_runs[sr1]]\n",
    "\n",
    "#list of runlists\n",
    "sr1_rl=[runlist for elem in sr1_rl for runlist in elem]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.errorbar(plot_dates, ch_df.loc[ch, sr1_rl] , yerr=[ch_lerr_df.loc[ch, sr1_rl], ch_uerr_df.loc[ch, sr1_rl]], linestyle='None', marker='.')\n",
    "plt.ylim(0.75, 1.1)\n",
    "plt.xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=20)\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "plt.grid()\n",
    "plt.title(\"Channel %s\" %ch)\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('spe acceptance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prints runlists with low acceptance for one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prints list of low acc runlists\n",
    "\n",
    "ch_accs=np.array(ch_df.loc[ch])\n",
    "\n",
    "low_acc=np.where(ch_accs<0.5)\n",
    "\n",
    "low_acc_rl=list(ch_df.columns[low_acc])\n",
    "        \n",
    "print('Low acc runlists for ch %s: ' %ch, low_acc_rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find outliers, plot the acceptance curve, acceptance histogram, and occupancy histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the index in run=outliers[index] in order to change which outlier gets plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find outliers, plot acc of one of them\n",
    "\n",
    "outlier_indices_low = np.array(np.where(accs < (evo_mean-1.5*evo_std))).flatten()\n",
    "outlier_indices_high= np.array(np.where(accs > (evo_mean+1.5*evo_std))).flatten()\n",
    "\n",
    "outlier_indices=outlier_indices_low.tolist() + outlier_indices_high.tolist()\n",
    "\n",
    "outliers = bottom_runs[outlier_indices]\n",
    "print(\"Outliers :\", outliers)\n",
    "run = outliers[0] #change index to change which outlier\n",
    "print('Run: ',run)\n",
    "runlist = file_to_list(find_file(run)[0])\n",
    "\n",
    "bot_run=runlist[0]\n",
    "tb_run=runlist[1]\n",
    "tr_run=runlist[2]\n",
    "\n",
    "x, acc, err = analyze.acceptance_curve_3runs(bot_run, tb_run, tr_run)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "for ch, a in enumerate(acc):\n",
    "    plt.plot(x, a, color='black', linewidth=1, alpha=0.6)\n",
    "    plt.title(\"Acceptance curve for: %d\" %run)\n",
    "    \n",
    "plt.xlim(-10, 200)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('spe acceptance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doesn't save the data\n",
    "thresholds = analyze.get_thresholds(analyze.find_regular_run(bot_run))\n",
    "acc, acc_errs, acc_sys, acc_stat = analyze.acceptance_3runs(bot_run, tb_run, tr_run, thresholds)\n",
    "occ, occ_sys, occ_stat = analyze.occupancy_3runs(bot_run, tb_run, tr_run)\n",
    "\n",
    "on_channels = np.where(occ > 0.05)[0]\n",
    "\n",
    "acc=acc[on_channels]\n",
    "occ=occ[on_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the occupancy of one runlist\n",
    "plt.hist(occ, bins=50, range=(0,1.1))\n",
    "plt.title(\"Occupancy for %s \" %find_file(run)[0])\n",
    "plt.xlabel(\"Occupancy\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlim(0,0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot the acceptance of one runlist\n",
    "plt.hist(acc, bins=50, range=(0,1.1))\n",
    "plt.title(\"Acceptance for %s \" %find_file(run)[0])\n",
    "plt.xlabel(\"SPE Acceptance\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runlist= find_file(run)[0]\n",
    "\n",
    "#plot acceptance of each channel\n",
    "plt.figure()\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.errorbar(on_channels, acc, yerr=[ch_lerr_df.loc[on_channels, runlist], ch_uerr_df.loc[on_channels,runlist]], marker='.', linestyle='none')\n",
    "plt.ylabel('Acceptance Fraction')\n",
    "plt.xlabel('Channel #')\n",
    "plt.title('Acc by Ch for %s' %runlist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cha_dict={}\n",
    "\n",
    "for ch, a in zip(on_channels, acc):\n",
    "    cha_dict[a]=ch\n",
    "    \n",
    "low_acc_ch=[]\n",
    "for a in acc:\n",
    "    if a<0.5:\n",
    "        low_acc_ch.append(cha_dict[a])\n",
    "        \n",
    "print('Low acc ch: ', low_acc_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
