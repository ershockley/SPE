{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SPE Acceptance #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook runs most of the code needed to do SPE acceptance studies. It starts by making runlists that are used to group the different types of SPE runs together. These runlists are used to download the rawdata if it is unavailable on midway, and then submit midway jobs to process the raw data in way needed for this study. After the jobs finish (~6 hours), the data is read in and plotted in various ways. \n",
    "\n",
    "See the python modules in this repository for more details, especially spe_acceptance.py and analyze.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rc('font', size=16)\n",
    "import matplotlib.pyplot as plt\n",
    "import analyze\n",
    "from channel_dict import channel_dict\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import pymongo \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pax.configuration import load_configuration\n",
    "import hax\n",
    "from hax.pmt_plot import plot_on_pmt_arrays, pmt_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Make runlists for any new runs that have been taken ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from make_runlist_new import write_spe_lists\n",
    "# dry run\n",
    "write_spe_lists(write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if happy with dry run, write the files\n",
    "wrote = write_spe_lists(write=True)\n",
    "print(\"We wrote these files:\")\n",
    "for f in wrote:\n",
    "    print('\\t' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"tmp_submit_file.txt\", \"w\") as f:\n",
    "    for file in wrote:\n",
    "        f.write(\"%s\\n\" % file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "./notebook_submit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "#### Check if jobs still running ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import time\n",
    "\n",
    "def jobs_running():\n",
    "    output = Popen([\"squeue\",\"--user\", os.environ['USER']], stdin=PIPE, stdout=PIPE, stderr=PIPE).stdout.read()\n",
    "    output = output.decode(\"utf-8\").split(\"\\n\")\n",
    "    jobs = len([l for l in output if 'spe' in l])\n",
    "    return (jobs > 0)\n",
    "\n",
    "# wait for jobs to finish\n",
    "print(\"waiting for jobs to finish\")\n",
    "while jobs_running():\n",
    "    print(\"..\", end='')\n",
    "    time.sleep(60)\n",
    "print(\"\\nDONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Use the same runlist files to read in the data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "uri = 'mongodb://eb:%s@xenon1t-daq.lngs.infn.it:27017,copslx50.fysik.su.se:27017,zenigata.uchicago.edu:270\\\n",
    "17/run'\n",
    "uri = uri % os.environ.get('MONGO_PASSWORD')\n",
    "c = pymongo.MongoClient(uri,\n",
    "                        replicaSet='runs',\n",
    "                        readPreference='secondaryPreferred')\n",
    "db = c['run']\n",
    "collection = db['runs_new']\n",
    "\n",
    "# get runlist files so that we know which runs go together\n",
    "def get_runlist_files(dir, exclude = []):\n",
    "    runlist_files = ['%s/%s' % (dir, f) for f in os.listdir(dir) if f.startswith(\"runlist\") and f not in exclude and f.endswith(\".txt\")]\n",
    "    return runlist_files\n",
    "\n",
    "# find a regular run from which to extract self trigger thresholds\n",
    "def find_regular_run(LED_run):\n",
    "    query = {'source.type' : {'$ne' : 'LED'},\n",
    "             '$and' : [{'number' : {'$lt': LED_run+20}}, \n",
    "                       {'number' : {'$gt' : LED_run-20}}\n",
    "                      ]\n",
    "            }\n",
    "    cursor = collection.find(query, {'number' : True,\n",
    "                                     'reader' : True,\n",
    "                                     '_id' : False})\n",
    "    \n",
    "    \n",
    "    \n",
    "    runs = np.array([run['number'] for run in cursor \n",
    "                     if any([ r['register'] == '8060' \n",
    "                             for r in run['reader']['ini']['registers']])])\n",
    "    \n",
    "    if LED_run < 5144: #when thresholds changed\n",
    "        runs = runs[runs<5144]\n",
    "    elif LED_run > 5144:\n",
    "        runs = runs[runs>5144]\n",
    "    diff = abs(runs - LED_run)\n",
    "    \n",
    "    closest_run = runs[np.argmin(diff)]\n",
    "    \n",
    "    return closest_run\n",
    "        \n",
    "    \n",
    "def get_threshold_changes():\n",
    "    cursor = collection.find(\n",
    "        {\n",
    "            \"tags.name\": \"_sciencerun0\", \n",
    "            #\"source.type\": \"AmBe\",\n",
    "            #\"data\": {\"$elemMatch\": {\"type\": \"processed\", \"pax_version\": \"v6.4.2\", \"host\": \"midway-login1\"}}\n",
    "        }).sort(\"number\", 1)\n",
    "\n",
    "\n",
    "    # Loop\n",
    "    st_list = []\n",
    "\n",
    "    st_changes = []\n",
    "    for doc in cursor:\n",
    "\n",
    "        # Record self-trigger thresholds\n",
    "        checklist = []\n",
    "        for register in doc['reader']['ini']['registers']:\n",
    "            if register['register'][-2:] == '60':\n",
    "                checklist.append(register)\n",
    "        sortedcheck = sorted(checklist, key=lambda k: k['register'])\n",
    "\n",
    "        if sortedcheck != st_list:\n",
    "            #print(\"Registers changed run \" + str(doc['number']))\n",
    "            st_changes.append(doc['number'])\n",
    "            st_list = sortedcheck\n",
    "    return st_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "runlist_files = get_runlist_files('/home/ershockley/analysis/SPE/runlists',\n",
    "                                  exclude = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "means = []\n",
    "medians = []\n",
    "stds = []\n",
    "bot_runs = []\n",
    "\n",
    "n_bins = 40\n",
    "\n",
    "acc_array = np.ones((len(runlist_files), len(channel_dict['all_channels'])))\n",
    "\n",
    "\n",
    "for file, runlist in enumerate(sorted(runlist_files)):\n",
    "    runlist = runlist.split('/')[-1].split('_')\n",
    "    bottom_run = int(runlist[1])\n",
    "    topbulk_run = int(runlist[2])\n",
    "    topring_run = int(runlist[3][:-4])\n",
    "    csv_file = \"./acceptance_data/acceptances_%d_%d_%d.csv\" % (bottom_run, topbulk_run, topring_run)\n",
    "    \n",
    "    #if os.path.exists(csv_file):\n",
    "    #    continue\n",
    "        \n",
    "        \n",
    "    existing_files = [os.path.exists('/home/ershockley/analysis/SPE/data/run_%d' % r)\n",
    "                        for r in [bottom_run, topbulk_run, topring_run]]\n",
    "    if not all([os.path.exists('/home/ershockley/analysis/SPE/data/run_%d' % r)\n",
    "                for r in [bottom_run, topbulk_run, topring_run]]):\n",
    "        missing_runs = [str(run) for run, boo in zip([bottom_run, topbulk_run, topring_run],\n",
    "                                               existing_files) if not boo]\n",
    "        print(\"Missing data for runs %s\" % \",\".join(missing_runs))\n",
    "        continue\n",
    "    \n",
    "    threshold_run = find_regular_run(bottom_run)\n",
    "    print(\"Threshold run: %d\" % threshold_run)\n",
    "    try:\n",
    "        thresholds = analyze.get_thresholds(threshold_run)\n",
    "    except KeyError:\n",
    "        thresholds = analyze.get_thresholds(threshold_run + 1)\n",
    "        \n",
    "    acceptances = analyze.get_acceptances_3runs(bottom_run, topring_run, \n",
    "                                                topbulk_run, thresholds, plot=True)\n",
    "    \n",
    "    \n",
    "    acc_array[file, :] *= acceptances\n",
    "    \n",
    "\n",
    "    with open(csv_file, \"w\") as f:\n",
    "        f.write(\"channel,acceptance\\n\")\n",
    "        for ch, acc in enumerate(acceptances):\n",
    "            f.write(\"%d,%0.4f\\n\" % (ch, acc))\n",
    "        \n",
    "    on_accs = acceptances\n",
    "    on_accs = np.delete(on_accs, analyze.excluded_pmts)\n",
    "    \n",
    "    means.append(np.mean(on_accs))\n",
    "    medians.append(np.median(on_accs))\n",
    "    stds.append(np.std(on_accs))\n",
    "    bot_runs.append(bottom_run)\n",
    "    plt.figure()\n",
    "    acc_hist, bins, patches = plt.hist(acceptances, bins = n_bins, range = (0,1))\n",
    "    plt.title(\"Runs %d %d %d\" % (bottom_run, topbulk_run, topring_run))\n",
    "    plt.xlabel(\"SPE acceptance fraction\")\n",
    "    plt.ylabel(\" # channels / bin (%d bins)\" % n_bins)\n",
    "    plt.show()\n",
    "    #plt.savefig(\"/project/lgrandi/xenon1t/spe_acceptance/plots/hist_%d-%d-%d.png\" % \n",
    "    #        (bottom_run, topbulk_run, topring_run))\n",
    "    \n",
    "print('DONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot all occupancies as a function of run number\n",
    "def get_occ(c):\n",
    "    return -1*np.log(c)\n",
    "\n",
    "run_numbers=[]\n",
    "\n",
    "all_run_numbers=[]\n",
    "\n",
    "bottom_runs=[]\n",
    "topb_runs=[]\n",
    "\n",
    "topring_runs=[]\n",
    "\n",
    "start_run = 6731\n",
    "end_run = 1e6\n",
    "\n",
    "\n",
    "datadir = 'acceptance_data'\n",
    "acceptance_dict = {}\n",
    "\n",
    "#adjusted for higher occs\n",
    "for file in os.listdir(datadir):\n",
    "    runs=file.split('_')\n",
    "    bottom_run = int(runs[1])\n",
    "    topb_run=int(runs[2])\n",
    "    topring_run=int(runs[3].split('.')[0])\n",
    "    \n",
    "    if not (start_run < bottom_run < end_run):\n",
    "         continue \n",
    "            \n",
    "#    if topb_run!=topring_run:\n",
    "#        continue\n",
    "    else:\n",
    "        bottom_runs.append(bottom_run)\n",
    "        topb_runs.append(topb_run)\n",
    "        topring_runs.append(topring_run)\n",
    "        all_run_numbers.append(bottom_run)\n",
    "        #all_run_numbers.append(topb_run)\n",
    "        all_run_numbers.append(topring_run)    \n",
    "    \n",
    "    data = pd.read_csv(datadir+'/'+file)\n",
    "    \n",
    "    acceptance_dict[bottom_run] = data['acceptance'].values \n",
    "\n",
    "for file, runlist in enumerate(sorted(runlist_files)):\n",
    "    runlist = runlist.split('/')[-1].split('.')[0].split('_')[1:]\n",
    "    for number in runlist:            \n",
    "        run_numbers.append(number)\n",
    "        \n",
    "run_numbers = [int(r) for r in run_numbers]\n",
    "all_run_numbers=sorted(all_run_numbers)\n",
    "\n",
    "ch, corr = analyze.get_corrections(run_numbers[0])\n",
    "plt.hist(get_occ(corr), bins=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#all runs\n",
    "corrections=np.ones((len(all_run_numbers), 248))\n",
    "occs = np.ones_like(corrections)\n",
    "occ_df = {}\n",
    "\n",
    "for i, run in enumerate(all_run_numbers):\n",
    "    ch, corr=analyze.get_corrections(run)\n",
    "    #corrections[i] = corr\n",
    "    #occs[i] = get_occ(corr)\n",
    "    occ_df[run] = get_occ(corr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "occ_df = pd.DataFrame(occ_df)\n",
    "\n",
    "\n",
    "occ_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skip_runs = []\n",
    "for run, occ in zip(tmp_bot_runs, bottom_occs):\n",
    "    if occ < 0.1:\n",
    "        print('low', run)\n",
    "    elif occ > 0.5:\n",
    "        print('high', run)\n",
    "    elif 0.1 < occ< 0.36:\n",
    "        print('slightly low', run)\n",
    "        \n",
    "    if (occ<0.36) or (occ>0.5):\n",
    "        skip_runs.append(run)\n",
    "        \n",
    "skip_runs = np.array(skip_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot SPE acceptance as function of time #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sorted(bot_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in data files\n",
    "\n",
    "evo_data = pd.DataFrame(acceptance_dict)\n",
    "\n",
    "#bad_bot_runs=[13837, 13433, 14088]\n",
    "#for i in bad_bot_runs:\n",
    "#    del evo_data[i]\n",
    "\n",
    "#evo_data = evo_data.drop(12512)\n",
    "#evo_data = evo_data.drop(skip_runs, axis=1)\n",
    "evo_data.head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(evo_data.columns, evo_data.index)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.pcolor(xx, yy, evo_data.values, cmap='viridis_r', vmin=0.5, vmax=1.0)\n",
    "plt.title(\"SPE acceptance evolution per channel\")\n",
    "plt.xlabel(\"Run number\")\n",
    "plt.ylabel(\"Channel\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neg_channels = []\n",
    "for ch, row in evo_data.iterrows():\n",
    "    if min(row.tolist()) < 0:\n",
    "         neg_channels.append(ch)\n",
    "print(neg_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# can now look at acceptace for individual run\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.dates import DayLocator, MonthLocator, DateFormatter, drange, AutoDateFormatter, AutoDateLocator\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_channel_evo(channel, dataframe, vlines=None):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    #times = [get_run_time(run) for run in dataframe.columns]\n",
    "    plt.scatter(dataframe.columns, dataframe.loc[[channel]])\n",
    "    plt.title('Channel %d' % channel)\n",
    "    plt.ylabel('SPE acceptance fraction')\n",
    "    plt.xlabel('Run number')\n",
    "    plt.ylim(-0.05, 1.1)\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.grid(True) #(b=True, which='major', color='0.65',linestyle='-')\n",
    "#    ax.xaxis.set_major_locator(MonthLocator())\n",
    "#    ax.xaxis.set_minor_locator(DayLocator())\n",
    "#    locator = AutoDateLocator()\n",
    "#    ax.xaxis.set_major_formatter(DateFormatter(\"%b '%y\"))\n",
    "    if vlines is not None:\n",
    "        n_regions = len(vlines) + 1\n",
    "        regions = []\n",
    "        for line in vlines:\n",
    "            regions.append(r for r in dataframe.columns if r < line)\n",
    "            print(np.mean(dataframe[regions].loc[[channel]]))\n",
    "#            plt.axvline(get_run_time(line))\n",
    "            plt.axvline(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## plot average acceptance vs run number ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ignore off channels (acceptance < 0.05)\n",
    "\n",
    "def custom_mean(df):\n",
    "    new_means = []\n",
    "    for col in sorted(df):\n",
    "        new_vals = [val for val in df[col] if val > 0.05]\n",
    "        new_means.append(np.mean(new_vals))\n",
    "    d = {}\n",
    "    for i, mean in enumerate(new_means):\n",
    "        d[df.columns[i]] = mean\n",
    "    return pd.DataFrame(d, index=['mean'])\n",
    "\n",
    "def custom_median(df):\n",
    "    new_meds = []\n",
    "    for col in sorted(df):\n",
    "        new_vals = [val for val in df[col] if val > 0.05]\n",
    "        new_meds.append(np.median(new_vals))\n",
    "    d = {}\n",
    "    for i, med in enumerate(new_meds):\n",
    "        d[df.columns[i]] = med\n",
    "    return pd.DataFrame(d, index=['median'])\n",
    "\n",
    "def custom_quantile(df, q):\n",
    "    new_qs = []\n",
    "    for col in sorted(df):\n",
    "        new_vals = [val for val in df[col] if val > 0.05]\n",
    "        new_qs.append(np.percentile(new_vals, q))\n",
    "    d = {}\n",
    "    for i, val in enumerate(new_qs):\n",
    "        d[df.columns[i]] = val\n",
    "    return pd.DataFrame(d, index=['%d_percentile'%q])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fluctuations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def group_list(runlist):\n",
    "    runlist = np.array(sorted(runlist))\n",
    "    indices  = np.where(runlist[:-1] - runlist[1:] != -1)[0]\n",
    "    starts = runlist[np.insert(indices + 1, [0], 0)]\n",
    "    ends = runlist[np.append(indices, [-1])]\n",
    "    return [(start, end) for start, end in zip(starts, ends)]\n",
    "\n",
    "def run_ranges(source, **kwargs):\n",
    "    runlist = runs_by_source(source, **kwargs)\n",
    "    return group_list(runlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from runDB import runs_by_source\n",
    "kr = runs_by_source('Kr83m', num_range=(6000, 16000))\n",
    "rn = runs_by_source('Rn220', num_range=(6000, 16000))\n",
    "bkg = runs_by_source('none', num_range=(6000, 16000))\n",
    "kr_ranges = group_list(kr)\n",
    "rn_ranges = group_list(rn)\n",
    "bkg_ranges = group_list(bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import hax\n",
    "hax.init()\n",
    "\n",
    "def get_run_time(run):\n",
    "    return hax.runs.datasets[hax.runs.datasets.number == run].start.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dates = [get_run_time(run) for run in evo_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Noise evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "noise_runs = []\n",
    "noise_rms = []\n",
    "noise_errors = [[],[]]\n",
    "\n",
    "with open('/home/ershockley/analysis/SPE/noise_rms.csv') as f:\n",
    "    for num, line in enumerate(f.readlines()):\n",
    "        if num==0:\n",
    "            continue\n",
    "        line = line.split(',')\n",
    "        run, rms, lower, upper = int(line[0]), float(line[1]), float(line[2]), float(line[3])\n",
    "        noise_runs.append(run)\n",
    "        noise_rms.append(rms)\n",
    "        noise_errors[0].append(lower)\n",
    "        noise_errors[1].append(upper)\n",
    "        \n",
    "noise_dates = [get_run_time(run) for run in noise_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sorted(bottom_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bad_runs = [6169, 10877, 11069, 12211, 12511, 12768, 13837]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for col in evo_data.coli,ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "fmt = mdates.DateFormatter('%Y-%m')\n",
    "\n",
    "thresh_change = get_run_time(6845)\n",
    "\n",
    "median = custom_median(evo_data).values[0]\n",
    "lower = custom_quantile(evo_data, 16).values[0]\n",
    "upper = custom_quantile(evo_data, 84).values[0]\n",
    "lower = median-lower\n",
    "upper = upper-median\n",
    "\n",
    "cut_range = (0.93, 0.96)\n",
    "f, ax = plt.subplots(figsize=(14,10))\n",
    "#ax.scatter(dates, custom_mean(evo_data).values[0],\n",
    "#           label = 'average SPE acceptance', color='navy')\n",
    "\n",
    "ax.errorbar(dates, median,\n",
    "            label='SPE acceptance', color='black', linestyle='None', \n",
    "            marker='.')\n",
    "ax.axvline(thresh_change, color='navy')\n",
    "ax.text(0.06, 0.9, 'threshold change', transform=ax.transAxes, color='navy')\n",
    "ax.set_ylabel('SPE acceptance')\n",
    "ax.set_xlabel('Date')\n",
    "ax.grid() \n",
    "ax.set_ylim(0.75, 1.05)\n",
    "\n",
    "plt.xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=20)\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(fmt)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "#ax2.scatter(dates, noise_sigmas, color='red', s=40)\n",
    "ax2.errorbar(noise_dates, noise_rms,\n",
    "             color='red', linestyle='None', marker='.')\n",
    "ax2.set_ylabel('noise RMS [ADC counts]', color='red')\n",
    "ax2.tick_params('y', colors='red')\n",
    "ax2.set_ylim(1, 6)\n",
    "#ax2.legend(loc=(0.05, 0.82))\n",
    "plt.savefig('time_evolution_noise.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "changes = []\n",
    "thresholds = []\n",
    "previous_threshold=0\n",
    "for run in sorted(bottom_runs):\n",
    "    regrun = find_regular_run(run)\n",
    "    thresh = analyze.get_thresholds(regrun)\n",
    "    thresholds.append(thresh)\n",
    "    mean_threshold = np.mean(thresh)\n",
    "    print(run, regrun, mean_threshold)\n",
    "    if mean_threshold != previous_threshold:\n",
    "        changes.append(run)\n",
    "    previous_threshold=mean_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.mean(thresholds[2][:247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_thresholds = thresholds[0]\n",
    "new_thresholds = thresholds[2]\n",
    "\n",
    "with open('thresholds.txt', 'w') as f:\n",
    "    header = '^channel^before run 6893^after run 6893^'\n",
    "    print(header)\n",
    "    f.write(header + '\\n')\n",
    "    for ch, (old, new) in enumerate(zip(old_thresholds, new_thresholds)):\n",
    "        if ch > 247:\n",
    "            continue\n",
    "        line = '|%d|%d|%d|' % (ch, old, new)\n",
    "        print(line)\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "changed_channels = {}\n",
    "for run in changes:\n",
    "    print(run)\n",
    "    index = sorted(bottom_runs).index(run)\n",
    "    if index==0:\n",
    "        print('skipping first run')\n",
    "        continue\n",
    "    prev_run = sorted(bottom_runs)[index - 1]\n",
    "    thresh = thresholds[index]\n",
    "    prev_thresh = thresholds[index-1]\n",
    "    changed_channels[run] = np.where(thresh-prev_thresh != 0)\n",
    "    \n",
    "print(changed_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Acceptance for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regions = [(0,6844), (6845, 99999)]\n",
    "per_ch_means = []\n",
    "\n",
    "for r in regions:\n",
    "    tmp = evo_data.drop(evo_data.columns[evo_data.columns < r[0]], axis=1)\n",
    "    tmp = tmp.drop(tmp.columns[tmp.columns > r[1]], axis=1)\n",
    "    tmp['mean'] = tmp.apply(np.mean, axis=1)\n",
    "    per_ch_means.append(tmp['mean'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "per_ch_means = np.array(per_ch_means)\n",
    "print('^ch^acceptance before run 6893^acceptance after run 6893')\n",
    "for ch in range(248):\n",
    "    before, after = per_ch_means[:,ch][0], per_ch_means[:,ch][1]\n",
    "    print('|%d|%0.2f|%0.2f|'%(ch, before, after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('mean before: ',np.mean([val for val in per_ch_means[0] if val > 0.05]))\n",
    "print('mean after: ',np.mean([val for val in per_ch_means[1] if val > 0.05]))\n",
    "\n",
    "print('median before: ',np.median([val for val in per_ch_means[0] if val > 0.05]))\n",
    "print('median after: ',np.median([val for val in per_ch_means[1] if val > 0.05]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Runs where we saw changes in low acceptance pmts ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# retrieve low acceptance pmts\n",
    "\n",
    "low_acc_dict = {}\n",
    "\n",
    "for col in evo_data:\n",
    "    low_acc_dict[col] = [ch for ch, a in enumerate(evo_data[col]) if a < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "low_acc_pmts = []\n",
    "for run, l in low_acc_dict.items():\n",
    "    low_acc_pmts = list(set(low_acc_pmts).union(set(l)))\n",
    "    \n",
    "print(sorted(low_acc_pmts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "last_list = 'init'\n",
    "changes = {}\n",
    "for key in sorted(low_acc_dict):\n",
    "    this_list = sorted(low_acc_dict[key])\n",
    "    if last_list == 'init':\n",
    "        last_list = this_list\n",
    "        \n",
    "    if this_list != last_list:\n",
    "        changed_pmts = set(last_list).symmetric_difference(set(this_list))\n",
    "        changes[key] = changed_pmts\n",
    "        \n",
    "    last_list = this_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s = \"Runs where we saw changes in low acceptance PMTS, and the PMTS that changed\"\n",
    "print(s)\n",
    "print(\"-\" * len(s))\n",
    "\n",
    "for run in sorted(changes):\n",
    "    print(run, changes[run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot the evolution of the pmts that changed:\n",
    "pmts_that_changed = []\n",
    "for run in changes:\n",
    "    for ch in changes[run]:\n",
    "        pmts_that_changed.append(ch)\n",
    "\n",
    "for ch in pmts_that_changed:\n",
    "    plot_channel_evo(ch, evo_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_channel_evo(137, evo_data)\n",
    "dplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
